
# üí° RAG Chatbot Input Flows (Text / File / Ask About File / Interactive Speech)

This document explains how different input types are handled by the RAG chatbot agent using LangChain + Gemini API.

---

## üß† Shared Stack

- **LangChain** ‚Äì Retrieval, document loaders, vector store
- **Gemini API** ‚Äì Embeddings and chat model (`gemini-1.5-flash`)
- **FastAPI** ‚Äì Web API
- **Chroma / FAISS** ‚Äì Vector storage for context retrieval
- **Whisper / STT** ‚Äì Speech-to-text transcription

---

## 1Ô∏è‚É£ Text Input Flow (`POST /text`)

### ‚ñ∂Ô∏è Flow

```
Frontend (text box)
  ‚Üì
POST /text
  ‚Üì
orchestrator.handle_text()
  ‚Üì
Gemini Embedding ‚Üí Vector Store Retrieval
  ‚Üì
Context + Query ‚Üí Gemini Chat
  ‚Üì
Return Response
```

### ‚úÖ Example

```json
POST /text
{
  "query": "What is Myanmar's data privacy policy?"
}
```

---

## 2Ô∏è‚É£ File Upload Flow (`POST /file`)

### ‚ñ∂Ô∏è Flow

```
Frontend (upload .pdf, .docx, .txt)
  ‚Üì
POST /file
  ‚Üì
file_parser.extract_text()
  ‚Üì
Split ‚Üí Embed ‚Üí Store in Vector DB (with file_id or user session)
  ‚Üì
Acknowledge Upload (file reference returned)
```

### ‚úÖ Example

```http
POST /file
Content-Type: multipart/form-data
file: cyberlaw_2024.pdf
```

**Response:**
```json
{
  "message": "File uploaded and indexed.",
  "file_id": "f123-cyberlaw"
}
```

---

## 3Ô∏è‚É£ Text: Ask About a File (`POST /text-with-file`)

### ‚ñ∂Ô∏è Flow

```
Frontend (text + file_id)
  ‚Üì
POST /text-with-file
  ‚Üì
orchestrator.handle_file_question(query, file_id)
  ‚Üì
Retrieve embeddings only from that file (context)
  ‚Üì
Context + Question ‚Üí Gemini Chat
  ‚Üì
Return Answer
```

### ‚úÖ Example

```json
POST /text-with-file
{
  "file_id": "f123-cyberlaw",
  "query": "Does this law mention data encryption?"
}
```

**Key**: Keeps file context **separate** from global chat memory.

---

## 4Ô∏è‚É£ Interactive Speech Conversation (`POST /speech`)

### ‚ñ∂Ô∏è Flow

```
Frontend: record ‚Üí send voice
  ‚Üì
POST /speech
  ‚Üì
speech_to_text(audio) ‚Üí transcribed_text
  ‚Üì
orchestrator.handle_text(transcribed_text)
  ‚Üì
RAG + Gemini as in text flow
  ‚Üì
Return:
  - Final response
  - Transcription (for frontend display)
```

### ‚úÖ Example

```http
POST /speech
Content-Type: multipart/form-data
file: audio_question.wav
```

**Response:**
```json
{
  "transcription": "Is this law applicable to social media?",
  "response": "Yes, it applies to platforms that collect personal data..."
}
```

---

## ‚úÖ Summary Table

| Mode                  | Input Type        | Preprocessing         | Context Source           | Endpoint             |
|-----------------------|-------------------|------------------------|---------------------------|-----------------------|
| Text Chat             | Text (plain)      | Optional normalization | Full vector DB            | `/text`              |
| File Upload           | PDF/DOCX/TXT      | File to text + embed   | Adds new context to DB    | `/file`              |
| Ask About File        | Text + file_id    | Clean query            | Vectors from that file    | `/text-with-file`    |
| Interactive Speech    | Audio (speech)    | STT ‚Üí Text             | Same as text flow         | `/speech`            |

---

## üõ°Ô∏è Notes

- `file_id` can be per-user/session for private document storage
- Speech flow can be extended for **voice-to-voice** loop using TTS
- Context length management is handled in LangChain pipeline

---

## üõ†Ô∏è Future Enhancements

- ‚úÖ Add support for multiple file references per query
- ‚úÖ Stream Gemini responses for faster UX
- ‚úÖ Add chat memory for follow-ups
- ‚úÖ Voice agent mode with response playback (TTS)
